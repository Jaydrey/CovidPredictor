{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aab978-086c-40f4-b0c0-7a1c09c7bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8473961a-f748-4241-ad48-7f764ec55985",
   "metadata": {},
   "outputs": [],
   "source": [
    "corona = pd.read_csv('clean_covid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568488a8-3328-448a-8f7d-0dee431c01c8",
   "metadata": {},
   "source": [
    "# Feature engineering  \n",
    "In this section we want to transform our data so that it can be ready to be fed to the model that we will be creating next.\n",
    "This involves a couple of things:\n",
    "1. Encoding our data\n",
    "2. Feature selection - determining the important columns that we will be using in our models\n",
    "3. Splitting our data to the train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7f9d2e-7a42-47e7-8219-7fbbad4f4a51",
   "metadata": {},
   "source": [
    "### Encode our data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade0b5a5-fcd1-4a48-bb96-76b64c15f618",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddd576d-85cd-4c29-8845-41fe66abd8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in corona.columns:\n",
    "    if corona[col].dtype=='O':\n",
    "        corona[col] = encoder.fit_transform(corona[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ceaa98-c67d-476c-8607-6e733a2cab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "corona.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00699de2-553d-44cf-9199-d6cb8018e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the dataset for use in data visualization\n",
    "corona.to_csv('clean_transformed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08fcf94-4d8a-4641-a38d-1c3712b0396b",
   "metadata": {},
   "source": [
    "### Select the most relevant feature columns to be used in our models\n",
    "For this we will use SelectKBest method that will rank our feature columns from the highest score to lowest.\n",
    "We will also use a heatmap to look at the correlation between our columns for selection putposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0378b412-2afd-4a0d-98c3-82d7591e4c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = corona.drop(['corona_result', 'test_date'], axis=1)\n",
    "y = corona['corona_result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9a62ce-7fda-44b5-b403-58343ee9e6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the chi square is our score function that will run the algorithm to determine the score of each column\n",
    "X_new = SelectKBest(chi2, k=6).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82542ab5-a551-4b3c-9183-ba6fafbef7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scores = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4ba886-6107-4742-9544-5511e7bfa1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scores['Specs'] = X.columns\n",
    "feature_scores['Score'] = X_new.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444e8021-3021-4499-be17-01ad4d1f4fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scores.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37af4c1-eef9-4aa4-8469-39aab3935b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## gender, test_date and possibly cough have scored the lowest thus might be omitted as one of the feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65da0813-1206-444b-bf45-f85a7ba50238",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Checking for correlations\n",
    "corr = corona.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, cmap='autumn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e439bf-ffb5-4f12-b0fc-f9601905d2e2",
   "metadata": {},
   "source": [
    "### Handling Imbalanced data\n",
    "In this section we will check on imbalancement in our label or target data. We do this to minimize overfitting or underfitting of our model. Our label data is said to be imbalanced if suppose it has a factor level 2(two values), if the ratio of appearance of the first value is 95% or more than the other value, then there is an imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7846ce-f328-4a17-88b1-4ee2d92a7da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efdf322-d02a-40a3-a67c-033dfb0694fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_0 = 100 * (y.value_counts()[0]/y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342671ab-cdbd-4374-9455-b21d5347a14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35884aad-3817-48dc-a87e-ff32abaf30ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## THE ration of 0 and 1 is 3 to 7 respectively so our target variable data is not imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dde177-84f1-4610-900f-c8132938899b",
   "metadata": {},
   "source": [
    "### Splitting our data to training and testing sets\n",
    "For this we have to split our data into training data and testing data. In training data we have the training feature data or x_train and training label data or y_train. Same goes for testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94983826-90ab-4c33-83a1-9ce026156f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = corona.drop(['corona_result', 'test_date', 'gender', 'cough'], axis=1)\n",
    "y = corona['corona_result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd71ff41-bd87-49a5-8e8d-679ce6931503",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525d278b-e028-4e1a-8497-8fbfaa2fa90f",
   "metadata": {},
   "source": [
    "### Training our data\n",
    "We can start by creating our machine learning model and use the x and y trains to train our data while the testing data we will use to test our models and get accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b983558-d909-4667-b95f-f9c4bf5aed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a pipeline for constructing our model and use the standard scaler\n",
    "def training_model(model):\n",
    "    pipe = make_pipeline(StandardScaler(), model)\n",
    "    pipe.fit(x_train, y_train)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b670b3eb-4e53-4393-b344-bc7c2fc8a47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = training_model(LogisticRegression())\n",
    "svc_model = training_model(SVC())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9997c146-be81-442b-a924-1d1c0056911b",
   "metadata": {},
   "source": [
    "#### Training Decision Tree and Random forest model by tweaking there parameter\n",
    "For this two models, I would like to train it in a different way so that I can tweak the parameters inside it to find optimum number of trees or/and nodes for these models. We can use the GridSearch to get the best parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3271b64f-4ff9-492e-8c11-dcf8f31ec529",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "dtc = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9892b75b-d4ff-403b-9099-0b4b57a9c9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_params():\n",
    "    rfc_params = {\n",
    "        'n_estimators': [2, 5, 10, 50],\n",
    "        'min_samples_split': [1,2,3,5],\n",
    "        'min_samples_leaf': [1,2,3,5],\n",
    "        'max_features': ['auto', 'sqrt', 'log2']\n",
    "    #     'max_depth' : [4,5,6,7,8],\n",
    "    }\n",
    "    CV_rfc = GridSearchCV(estimator=rfc, param_grid=rfc_params, cv=5)\n",
    "    CV_rfc.fit(x_train, y_train)\n",
    "    return CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c0e50b-f5f4-4613-a926-9925d7079e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'max_features': 'log2', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e96900-33ba-4079-85f3-812b24eec841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the best params to use for the random Forest\n",
    "print(best_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ae1d09-a4a2-4478-b7c4-a2e5a3b7bc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training our model\n",
    "rfc_model = training_model(RandomForestClassifier(n_estimators=2, min_samples_split=3, min_samples_leaf=5, max_features='log2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c8c6ab-1e40-4a5d-9e17-2cb69d014279",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f396f5-2231-48b3-98e2-c47e5edba0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_best_param():\n",
    "    dt_params = {\n",
    "        'min_samples_split': [1,2,3,5,10],\n",
    "        'max_leaf_nodes': [2,3,5,10,20,50],\n",
    "        'min_samples_leaf': [1,2,3,5,10]\n",
    "    }\n",
    "    CV_dt = GridSearchCV(estimator=dt, param_grid=dt_params, cv=5)\n",
    "    CV_dt.fit(x_train, y_train)\n",
    "    return CV_dt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9780eea9-41da-4c7b-81c5-2804878b8b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt_best_param())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cece345-f74e-4b8a-bed3-035d15dd724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = training_model(RandomForestClassifier(max_leaf_nodes=10, min_samples_leaf=1, min_samples_split=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c597fd5-902d-4b3b-a52c-eb9532cf1b5b",
   "metadata": {},
   "source": [
    "### Let's test out our model to see it's accuracy\n",
    "We will also use the accuracy score as well as classification_report to get the entire report on each score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b1d953-d25d-4810-be97-8789500bd9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test your model using the testing model function\n",
    "def testing_model(model):\n",
    "    y_pred = model.predict(x_test)\n",
    "    score = metrics.accuracy_score(y_test, y_pred)\n",
    "    report = metrics.classification_report(y_test, y_pred)\n",
    "    return [score, report]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba65ef24-1c99-4c9f-b5bc-6bf8a575a133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print out the accuracy for each model created\n",
    "print(f'logistic regression: {testing_model(lr_model)[0]}')\n",
    "print(f'random forest: {testing_model(rfc_model)[0]}')\n",
    "print(f'decision tree: {testing_model(dt_model)[0]}')\n",
    "print(f'support vector classifier: {testing_model(svc_model)[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d4bcaf-11b4-40aa-aeec-ccf886353ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report on logistic regression model\n",
    "print(testing_model(lr_model)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3ee964-023b-4fd7-987d-a2a16f1f7d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report on random forest model\n",
    "print(testing_model(rfc_model)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef16e4d6-be74-4d69-814c-13b6445dc93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report on decision tree model\n",
    "print(testing_model(dt_model)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c2aeba-7f8b-4907-adbc-8a0777ea4bec",
   "metadata": {},
   "source": [
    "### Saving our model as .pkl extension using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b7b4aa-42ef-46ec-b773-403b6ec544b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## saving model inside the pickle module\n",
    "import pickle\n",
    "pickle.dump(rfc_model, open('rfc_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e51c22-78f5-4ba6-adbd-a238e6fd317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('rfc_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9730d9-ae23-441b-8d2f-ff3138e174e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_col = list(pred_df.columns.values)\n",
    "result = model.predict([[1, 0, 0, 0, 0, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c7bbd3-5fe6-49f1-8411-6ac6b4a50115",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
